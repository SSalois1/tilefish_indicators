---
title: "Environmental indicator analysis-Tilefish"
output:  
  html_document:
    code_fold: hide
    toc: true
    toc_depth: 5
    toc_float: true
    number_sections: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```


```{r, wrangling}

# Loading packages and data
library(ggplot2)
library(ecodata)
library(lubridate)
library(dplyr)
library(stringr)
library(marmap) # bathymetry
library(RColorBrewer)
library(ggnewscale)
library(sf)
library(cowplot)
library(tidyverse)
library(ggpubr)
library(sf)
library(ggdist)
library(ggpubr)
library(wesanderson)
library(raster)
library(mgcv)
#library(glmTMB)
library(ggpmisc)
library(mgcViz)
library(gratia)

# CPUE data (no env covariates)
gt_data_model_cpue <- read.csv(here::here('data/catch_data/gt_data_model_cpue.csv'))
 
# note: Paul indicated to use small mesh
gt_data_model_cpue <- gt_data_model_cpue %>% 
       rename_all(., .funs = tolower) %>% 
  mutate(mesh_bin = case_when(mesh_size <= 5.6 ~ 'SM',mesh_size >= 5.6 ~ 'LG',
                                                      TRUE ~ 'NA')) %>%
  mutate(cpue_hr = sum_gt_catch/effort_dur)

# Catch data: 
sfobs <-readRDS(here::here('data/catch_data/gold_tile_sf_ob_v1_temp_price.rds'))

sfob.env <- sfobs %>% 
  mutate(mesh_bin = case_when(mesh_size <= 5.6 ~ 'SM', mesh_size >= 5.6 ~ 'LG',
                              TRUE ~ 'NA'),
         cpue_hr = SUM_GT_CATCH/effort_dur) %>% 
  filter(YEAR %in% c(1998:2022) & mesh_bin == 'SM') %>%
  dplyr::select(DATE, YEAR, MONTH, YDAY,trip_id,hull_num, area, effort_dur, 
         SUM_GT_CATCH, cpue_hr, mesh_size, mesh_bin, depth, start_lat, start_lon,
         bottomT, bottomT_avg, MIN_TEMP_C, MEAN_TEMP_C, MAX_TEMP_C,
         TEMP_VARIANCE, TEMP_DEVIATION, MEAN_DPTH_M, tri, sed) %>% 
  mutate(YEAR = as.integer(YEAR)) %>% 
  rename_all(., .funs = tolower)

sort(unique(sfob.env$month))
hist(sfob.env$month)


areas <- sort(unique(sfob.env$area))
catch.tally.ann <- sfob.env %>% # aggregate by year
  group_by(year) %>% 
  summarise(ttl_sum = sum(sum_gt_catch))

# Recruitment estimates from 2021 report
recruit <- read.csv(here::here('data/assessment_data/tilefish_rec_estimate_2021.csv'))

# Merge SF/Obs catch data with recruit estimates:
catch_recruit <- cbind(recruit %>% filter(year %in% c(1998:2020)),
                       catch.tally.ann %>%
                         filter(year %in% c(1998:2020)) %>%
                         dplyr::select(ttl_sum))

# loading in shape files for maps
wd = here::here('shapefiles')
US.areas <- st_read(here::here('shapefiles/USA.shp'), quiet = TRUE)
canada.areas <- st_read(here::here('shapefiles/Canada.shp'), quiet = TRUE)
bts_strata <- st_read(here::here('shapefiles/NES_BOTTOM_TRAWL_STRATA.shp'),
                      quiet = TRUE)
# plot(bts_strata) # to see all bottom trawl strata

gtf_strata <- bts_strata %>% 
  filter(STRATUMA %in% c('01030', '01040', '01070', '01080', '01110', '01120', 
                         '01140', '01150', '01670', '01680', '01710', '01720', 
                         '01750', '01760')) # select just the gtf strata
# plot(gtf_strata)
bathy <- marmap::getNOAA.bathy(-81,-58, 27, 46)
bathy = fortify.bathy(bathy)

```



## Tilefish data
***

### Catch data

Year-class strength is broadly defined as the number of fish spawned or hatched 
in a given year (Ricker, 1975).


Figure 1. Sum of catch (not accounting for effort), across years. Light blue 
shaded region represents the temporal range of observer records and red 
shaded region represents temporal range of study fleet records. The 'purple' 
region is where they overlap. Note that 2000-2005 for observer records had 
low sample size/number of vessels for tilefish, making the shaded region likely 
the best region to use for analysis. The vertical dashed lines represent strong
year classes for this species (Nesslage et al. 2021). Red asterisk marks year
that stock was deemed 're-built'.

```{r, c1}
# tot_catch == total (sum_catch) across hauls. so if tallying up annually, 
# use sum_catch
# Strong year-classes: 1970, 1973, 1993, 1999, 2005, 2013

ggplot(catch.tally.ann, aes(x = factor(year), y = ttl_sum, group = 1))+
   geom_rect(aes(xmin = '2007', xmax = '2022', ymin = -Inf, ymax = Inf), 
            fill = 'red', alpha = 0.02) +
  geom_rect(aes(xmin = '2000', xmax = '2022', ymin = -Inf, ymax = Inf), 
            fill = 'lightblue', alpha = 0.05) +
   geom_vline(xintercept = c('1993','1999', '2005', '2013'), lty = 2) +
  geom_line(color = 'black', size = 1.5) +
  annotate("text", label = "*",
    x = 26, y = 14000, size = 8, colour = "red" )+
  xlab('Year') + 
  ylab('Total sum tilefish catch') + 
  # facet_wrap(~month)+
  theme(axis.text.x = element_text(color = 'black',
                                   size = 12, angle = 45, vjust = 1, hjust=1)) +
  ecodata::theme_facet()

```


#### CPUE 


Figure 2. Catch-per-unit-effot for undirected trawl trips from the Study fleet and 
observer program. Zeros have been added using species association methodology
(via jaccard index). 

[see here for example](https://static1.squarespace.com/static/511cdc7fe4b00307a2628ac6/t/64501a9ee391c8439cbc3c04/1682971295614/c_MRIP+Index_Drew+2022d.pdf)

```{r, c2}
gt_data_model_cpue %>% 
  filter(mesh_bin == 'SM') %>% # note: Paul indicated to use small mesh
  group_by(year, source) %>% 
  summarise(mean_cpue = mean(cpue_hr),.groups = 'drop') %>%
  ggplot(aes(x=year,y=mean_cpue)) +
  geom_line(lwd = 1) +
  facet_wrap(~source) + 
  theme_bw()

gt_data_model_cpue %>% 
  filter(mesh_bin == 'SM') %>%
  group_by(year) %>% 
  summarise(mean_cpue = mean(cpue_hr),.groups = 'drop') %>%
  ggplot(aes(x=year,y=mean_cpue)) +
  geom_line(lwd = 1) +
  labs(title = 'Study fleet + Observer combined') + 
  theme_bw()

```


#### Maps (catch) {.tabset}

Tilefish catch locations (study fleet/observer)

```{r, maps, results='asis'}

yrs = sort(unique(gt_data_model_cpue$year))    

#for(i in 1:length(yrs)){
yrmap <- function(yrs){
  gt_data_model_cpue %>% 
  filter(start_lat < 42.5 & depth_est > 50 & year == yrs) %>%
  mutate(bin = cut(year, seq(min(year), max(year) + 4, 4), right = FALSE)) %>%
  ggplot() + 
  geom_sf(data = US.areas %>% st_as_sf(),color = 'gray20', fill = '#cbdbcd') +
  geom_contour(data = bathy,
               aes(x=x,y=y,z=-1*z),
               breaks=c(50,100,150,200, Inf),
               size=c(0.3),
               col = 'darkgrey') +
  stat_summary_2d(aes(x=start_lon, y=start_lat, z = cpue_hr),
                  binwidth=c(0.16666,0.16666)) + 
  scale_fill_viridis_c() + 
  theme(legend.position = "bottom",
        legend.key.size = unit(0.2, "cm"),
        legend.key.width = unit(1, "cm")) +
  coord_sf(xlim = c(-75,-65.5), ylim = c(36,44), datum = sf::st_crs(4326))  +
  labs(x = '', y = '', fill = 'CPUE') +
  theme_bw() 
}


for(i in 1:length(yrs)){
 cat("\n#####",  as.character(yrs[i]),"\n")
    print(yrmap(yrs[i])) 
    cat("\n")   
}


```


### Environmental data
***

The strong year classes for Golden Tilefish were 1993, 1998, 2005, 2013. 
Some of the underlying oceanographic processes that may be related to recruitment
may influence habitat, retention/displacement and food availablity. These are
explored below. 


#### Habitat

Tilefish occupy a very narrow band of habitat conditions. Therefore, temperature 
and salinity may be of interest. 

##### SST

```{r, c9}
# SST
sst<-read.csv(here::here('data/sst/sst_ts_gtf_strata.csv'))
```

##### SST analysis

```{r}

# filter sfob.env - removes 2002 outlier
sfob <- sfob.env %>% filter(depth > 50, cpue_hr >0, cpue_hr < 15) %>%
  group_by(year,month) %>% 
  summarise(mean_cpue = mean(cpue_hr),
            mean_tri = mean(tri),
            mean_sed = mean(sed)) 
         
# Join with sf/ob data
sst.sfob <- dplyr::full_join(sst, sfob, by = join_by(year, month)) %>%
  dplyr::select(year, month, mean_cpue, mean_tri, mean_sed, mean_sst, weighted_mean_sst) %>%
  tidyr::drop_na()

```

**SST Regression and Correlation - No Lag**

```{r}
# Correlation and plot
lm_sst<-lm(weighted_mean_sst ~ mean_cpue, data=sst.sfob)
summary(lm_sst)

sst.sfob = sst.sfob %>%
  mutate(season = case_when(month %in% c(1,2,3) ~ 'winter', 
                            month %in% c(4,5,6) ~ 'spring', 
                            month %in% c(7,8,9) ~ 'summer', 
                            month %in% c(10,11,12) ~ 'fall'))

cor.test(sst.sfob$mean_cpue, sst.sfob$weighted_mean_sst, method=c("pearson"))

# all seasons, color coded
ggscatter(sst.sfob, x = "weighted_mean_sst", y = "mean_cpue", 
          add = "reg.line", conf.int = TRUE, 
          color ="season", palette = c("Spectral"),
          cor.coef = TRUE, cor.coeff.args = list(method="pearson"),
          add.params=list(color="dodgerblue", fill="lightgray"),
          xlab = "Weighted Mean SST", ylab = "Monthly Mean CPUE/hr",
          title = "Sea Surface Temperature")

# plot by season
sst.sfob %>% group_by(year, season) %>%
 ggscatter(x = "weighted_mean_sst", y = "mean_cpue", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.coeff.args = list(method="pearson"),
          add.params=list(color="dodgerblue", fill="lightgray"),
          xlab = "Weighted Mean SST", ylab = "Monthly Mean CPUE/hr",
          title = "Sea Surface Temperature")+
  facet_wrap(~season, scales = 'free')


```


##### Bottom Temperature

Figure 1. GLORYS vs in-situ bottom temperatures from study fleet vessels. 

Figure 2. Bottom temperature (C) across years. Blue dots are in-situ data, red
dots are from GLORYS. 

```{r, c11}

ggplot2::ggplot(sfob.env, aes(x=bottomt, y=mean_temp_c)) +
  geom_point(color="blue", alpha=0.1)+
  geom_abline(intercept = 0, slope = 1) +
  xlab('Bottom Temp (SF)') +
  ylab('Bottom Temp (GLORYS)') +
  theme_bw() 

ggplot2::ggplot(sfob.env, aes(x=bottomt, y=year)) +
  geom_point(color="blue", alpha=0.1) +
  geom_point(data = sfob.env, aes(x=mean_temp_c, y=year),
             color="red", alpha=0.1) +
  xlab('Bottom Temp') +
  ylab('Year') +
  labs(color = 'Source') +
  theme_bw() 

```

##### Bottom T analysis

The following figures compare in-situ bottom temperature from the study-fleet
data set to the Study fleet and Observer tilefish catch data. 

+ Note here temperatures are averaged across all depths > 50 for each month.


```{r}

bt.cpue = sfob.env %>% filter(year > 2006 & depth > 50 & cpue_hr > 0 & cpue_hr < 15) %>%
  group_by(year,month) %>% 
  summarise(mean_dpth = mean(depth),
            mean_bt = mean(bottomt),
            min_bt = min(bottomt),
            max_bt = max(bottomt),
            sd_bt = sd(bottomt),
            mean_tri = mean(tri),
            mean_sed = mean(sed),
            mean_cpue = mean(cpue_hr))

# See what months have data
sort(unique(bt.cpue$month))
hist(bt.cpue$month) 

```

**Bottom temp regression and correlation - Observer insitu bt - No Lag**

```{r}
lm_bt<-lm(mean_bt ~ mean_cpue, data=bt.cpue)
summary(lm_bt)

bt.cpue = bt.cpue %>%
  mutate(season = case_when(month %in% c(1,2,3) ~ 'winter', 
                            month %in% c(4,5,6) ~ 'spring', 
                            month %in% c(7,8,9) ~ 'summer', 
                            month %in% c(10,11,12) ~ 'fall'))

cor.test(bt.cpue$mean_cpue, bt.cpue$mean_bt, method=c("pearson"))

# all seasons, color coded by season
ggscatter(bt.cpue, x = "mean_bt", y = "mean_cpue", 
          add = "reg.line", conf.int = TRUE, 
          color ="season", palette = c("Spectral"),
          cor.coef = TRUE, cor.coeff.args = list(method="pearson"),
          add.params=list(color="dodgerblue", fill="lightgray"),
          xlab = "Mean bottom temp (°C)", ylab = "Monthly Mean CPUE/hr",
          title = "In-situ Bottom Temperature no lag")

# plot by season
bt.cpue %>% group_by(year, season) %>%
 ggscatter(x = "mean_bt", y = "mean_cpue", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.coeff.args = list(method="pearson"),
          add.params=list(color="dodgerblue", fill="lightgray"),
          xlab = "Mean bottom temp (°C)", ylab = "Monthly Mean CPUE/hr",
          title = "In-situ Bottom Temperature no lag")+
  facet_wrap(~season, scales = 'free')

```

**Regression for sf/ob CPUE and GLORYS bt - No Lag**

```{r}
#filter by year, depth, cpue, mean_temp_c
glorys.bt = sfob.env %>% filter(mean_temp_c > 0, depth > 50 & cpue_hr > 0 & cpue_hr < 15) %>%
  group_by(year,month) %>% 
  summarise(mean_tri = mean(tri),
            mean_sed = mean(sed),
            mean_cpue = mean(cpue_hr),
            mean_glorysbt = mean(mean_temp_c))

# Correlation and plot
lm_glorys<-lm(mean_glorysbt ~ mean_cpue, data=glorys.bt)
summary(lm_glorys)

glorys.bt = glorys.bt %>%
  mutate(season = case_when(month %in% c(1,2,3) ~ 'winter', 
                            month %in% c(4,5,6) ~ 'spring', 
                            month %in% c(7,8,9) ~ 'summer', 
                            month %in% c(10,11,12) ~ 'fall'))

cor.test(glorys.bt$mean_cpue, glorys.bt$mean_glorysbt, method=c("pearson"))
ggscatter(glorys.bt, x = "mean_glorysbt", y = "mean_cpue", 
          add = "reg.line", conf.int = TRUE, 
          color ="season", palette = c("Spectral"),
          cor.coef = TRUE, cor.coeff.args = list(method="pearson"),
          add.params=list(color="dodgerblue", fill="lightgray"),
          xlab = "Monthly Mean GLORYS Bottom Temperature", ylab = "Monthly Mean CPUE/hr",
          title = "GLORYS Bottom Temperature")
```


##### Salinity

Here we explore salinity from the GLORYS reanalysis model at three different 
depths

 + 55 meters (relevant to larvae, recruits)
 + 110 meters (relevant recruits, juveniles)
 + 220 meters (relevant to juveniles, adults)

##### Salinity analysis

```{r}
sal <- read.csv(here::here("data/study_fleet_obs_env.csv"))

#filter depth and remove CPUE outliers
sal = sal %>% filter(year > 1997 & depth > 50 & cpue_hr > 0 & cpue_hr < 15) %>%
  group_by(year,month) %>% 
  summarise(mean_sal = mean(btm_sal),
            mean_tri = mean(tri),
            mean_sed = mean(sed),
            mean_cpue = mean(cpue_hr)) %>%
   tidyr::drop_na()

#designate season
sal = sal %>%
  mutate(season = case_when(month %in% c(1,2,3) ~ 'winter', 
                            month %in% c(4,5,6) ~ 'spring', 
                            month %in% c(7,8,9) ~ 'summer', 
                            month %in% c(10,11,12) ~ 'fall'))

```

**Regression and correlation CPUE and salinity - No Lag**
```{r}
# all seasons, color coded by season
ggscatter(sal, x = "mean_sal", y = "mean_cpue", 
          add = "reg.line", conf.int = TRUE, 
          color ="season", palette = c("Spectral"),
          cor.coef = TRUE, cor.coeff.args = list(method="pearson"),
          add.params=list(color="dodgerblue", fill="lightgray"),
          xlab = "Monthly Mean Salinity (psu)", ylab = "Monthly Mean CPUE/hr",
          title = "Salinity No Lag")

# plot by season
sal %>% group_by(year, season) %>%
 ggscatter(x = "mean_sal", y = "mean_cpue", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.coeff.args = list(method="pearson"),
          add.params=list(color="dodgerblue", fill="lightgray"),
          xlab = "Monthly Mean Salinity (psu)", ylab = "Monthly Mean CPUE/hr",
          title = "Salinity No Lag")+
  facet_wrap(~season, scales = 'free')
```


#### Currents

Cross-shelf processes may influence the retention or displacement of tilefish 
during early life history stages. These are explored below.

##### Shelf water volume

Shelf water volume: A measure of the volume of water bounded inshore of the
shelf-slope front. In this analysis, shelf water is defined as all water having 
salinity <34 psu. The position of the shelf-slope front varies inter-annually
with the higher shelf water values indicating the front being pushed further 
towards the shelf break.

high shv: front pushed towards sbf
low shv: front pushed inshore (more slope water on shelf)

Hypothesis: Higher recruitment success correlated with years of higher shelf 
water volume in spring/summer. These months months may be particularly 
important as that is when spawning is occurring and the position of the sbf
may influence the position of larvae (away from spawning grounds).

Additional variables in this dataset are shelf water temperature and salinity 
which may also be indicative of habitat conditions. 


```{r, s.w.volume}

# Shelf water volume
shlfvol <- read.csv(here::here('data/shelf_water_volume/ShelfWaterVolume_BSB_update.csv'))

# wrangling date info, converting doy to date and month 
yrs <- as.vector(nrow(shlfvol))
shlfvol$Year <- as.character(shlfvol$Year)
for (i in 1:nrow(shlfvol)){
  yrs[i] <- strsplit(shlfvol$Year, ".", fixed = TRUE)[[i]][1]
}
shlfvol$year <- yrs
shlfvol <- shlfvol %>% mutate(date_= as.Date(Year.Day-1, 
                                             origin=paste0(year, "-01-01")), 
                              month= strftime(date_, "%m"), 
                              day=strftime(date_,"%d"), 
                              year = as.integer(year),
                              month = as.numeric(month))  

```

**Shelf water volume with Study fleet/Observer data**

```{r}
# Create shw vol by month w mean V, T, S
shlfvol = shlfvol %>%
  filter(year > 1997) %>%
  group_by(year,month) %>%
  summarise(mean_t = mean(ShW.T),
            mean_s = mean(ShW.S),
            mean_v = mean(ShW.Vol))

#filter sfob.env 
shlfvol.sfob = sfob.env %>% filter(depth > 50, cpue_hr > 0, cpue_hr<15) %>%
  group_by(year,month) %>% 
  summarise(mean_dpth = mean(depth),
            mean_bt = mean(bottomt),
            mean_cpue = mean(cpue_hr),
            mean_tri = mean(tri),
            mean_sed = mean(sed))

# Join with sf/ob data
df.shlfvol.sfob = dplyr::full_join(shlfvol.sfob, shlfvol, by = join_by(year, month)) %>%
  dplyr::select(year, month, mean_cpue, mean_tri, mean_sed, mean_t, mean_s, mean_v) %>%
  tidyr::drop_na()

#See what months have data
sort(unique(df.shlfvol.sfob$month))
hist(df.shlfvol.sfob$month)
```


**Regressions and correlation between sf/ob CPUE and shelf water volume/temp/salinity - No Lag**

```{r}
#shelf water volum

lm_shlf<-lm(mean_v ~ mean_cpue, data=df.shlfvol.sfob)
summary(lm_shlf)

df.shlfvol.sfob = df.shlfvol.sfob %>%
  mutate(season = case_when(month %in% c(1,2,3) ~ 'winter', 
                            month %in% c(4,5,6) ~ 'spring', 
                            month %in% c(7,8,9) ~ 'summer', 
                            month %in% c(10,11,12) ~ 'fall'))

cor.test(df.shlfvol.sfob$mean_cpue, df.shlfvol.sfob$mean_v, method=c("pearson"))

#all months, color coded by season
ggscatter(df.shlfvol.sfob, x = "mean_v", y = "mean_cpue", 
          add = "reg.line", conf.int = TRUE, 
          color="season", palette="Spectral",
          cor.coef = TRUE, cor.coeff.args = list(method="pearson"),
          add.params=list(color="dodgerblue", fill="lightgray"),
          xlab = "Mean shelf water volume", ylab = "Monthly mean CPUE/hr", title="Shelf Water Volume No Lag")

# by season
df.shlfvol.sfob %>% group_by(year, season) %>%
 ggscatter(x = "mean_v", y = "mean_cpue", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.coeff.args = list(method="pearson"),
          add.params=list(color="dodgerblue", fill="lightgray"),
          xlab = "Mean Shelf Water Volume", ylab = "Monthly Mean CPUE/hr",
          title = "Shelf Water Volume No Lag")+
  facet_wrap(~season, scales = 'free')

##############################################################
 
# shelf water temperature
lm_shlf_t<-lm(mean_t ~ mean_cpue, data=df.shlfvol.sfob)
summary(lm_shlf_t)

cor.test(df.shlfvol.sfob$mean_cpue, df.shlfvol.sfob$mean_t, method=c("pearson"))

#all months, color coded by season
ggscatter(df.shlfvol.sfob, x = "mean_t", y = "mean_cpue", 
          add = "reg.line", conf.int = TRUE, 
          color="season", palette="Spectral",
          cor.coef = TRUE, cor.coeff.args = list(method="pearson"),
          add.params=list(color="dodgerblue", fill="lightgray"),
          xlab = "Mean shelf water temperature", ylab = "Monthly mean CPUE/hr", title="Shelf Water Temperature No Lag")

#by season
df.shlfvol.sfob %>% group_by(year, season) %>%
 ggscatter(x = "mean_t", y = "mean_cpue", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.coeff.args = list(method="pearson"),
          add.params=list(color="dodgerblue", fill="lightgray"),
          xlab = "Mean Shelf Water Temperature", ylab = "Monthly Mean CPUE/hr",
          title = "Shelf Water Temperature No Lag")+
  facet_wrap(~season, scales = 'free')

##########################################################################

# shelf water salinity
lm_shlf_s<-lm(mean_s ~ mean_cpue, data=df.shlfvol.sfob)
summary(lm_shlf_s)

cor.test(df.shlfvol.sfob$mean_cpue, df.shlfvol.sfob$mean_s, method=c("pearson"))

ggscatter(df.shlfvol.sfob, x = "mean_s", y = "mean_cpue", 
          add = "reg.line", conf.int = TRUE, 
          color="season", palette="Spectral",
          cor.coef = TRUE, cor.coeff.args = list(method="pearson"),
          add.params=list(color="dodgerblue", fill="lightgray"),
          xlab = "Mean shelf water salinity", ylab = "Monthly mean CPUE/hr", title="Shelf Water Salinity No Lag")

# by season
df.shlfvol.sfob %>% group_by(year, season) %>%
 ggscatter(x = "mean_s", y = "mean_cpue", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.coeff.args = list(method="pearson"),
          add.params=list(color="dodgerblue", fill="lightgray"),
          xlab = "Mean Shelf Water Salinity", ylab = "Monthly Mean CPUE/hr",
          title = "Shelf Water Salinity No Lag")+
  facet_wrap(~season, scales = 'free')

```


##### Gulf-stream index

Gulf stream index was calculated based on method presented by 
Pérez-Hernández and Joyce (2014). The gulf stream index (GSI) is a measure of 
the degrees latitude above the average Gulf Stream position based on ocean
temperature at 200m (15 C) depth between 55W to 75W.

Positive values indicate a the mean position of the GS is more Northernly, 
whereas negative values indicate a more Southernly position. 

**GSI/recruitment year lags - comparison to Nesslage ea 2023**

```{r}
gsi.m <- read.csv(here::here('data/gulf_stream_index/mm_gsi_1954_2022_chen.csv'))
df <- dplyr::full_join(recruit, gsi.m %>%
                   group_by(year) %>% 
                   filter(month %in% c(3:8)) %>% 
                   summarise(m.gsi = mean(GSI),
                             sd.gsi = sd(GSI),
                             max.gsi = max(GSI), 
                             min.gsi = min(GSI)), 
                 by = join_by(year)) %>% 
  mutate(mean_gsi_lag1 = lag(m.gsi,1),
         mean_gsi_lag2 = lag(m.gsi,2),
         mean_gsi_lag3 = lag(m.gsi,3),
         mean_gsi_lag6 = lag(m.gsi,6),
         mean_gsi_lag7 = lag(m.gsi,7)) %>%
  mutate(pos = ifelse(m.gsi > 0, 'Northerly', 'Southerly'), 
         n.pos = ifelse(m.gsi > 0, 1, 0))
gsi_df <- df[-c(51:69),] 
gsi_df <- gsi_df[-c(13),] # removes recruitment outlier

## No lag
lm_rec_gsi<-lm(m.gsi ~ recruit_est, data=gsi_df)
summary(lm_rec_gsi)

cor.test(gsi_df$recruit_est, gsi_df$m.gsi, method=c("pearson"))

ggscatter(gsi_df, x = "m.gsi", y = "recruit_est",
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.coeff.args = list(method="pearson"),
          add.params=list(color="dodgerblue", fill="lightgray"),
          xlab = "Mean Yearly GSI", ylab = "Recruitment Estimate",
          title = "Recruitment No Lag")


## 1 year lag
lm_rec_gsi1<-lm(mean_gsi_lag1 ~ recruit_est, data=gsi_df)
summary(lm_rec_gsi1)

cor.test(gsi_df$recruit_est, gsi_df$mean_gsi_lag1, method=c("pearson"))

ggscatter(gsi_df, x = "mean_gsi_lag1", y = "recruit_est",
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.coeff.args = list(method="pearson"),
          add.params=list(color="dodgerblue", fill="lightgray"),
          xlab = "Mean Yearly GSI", ylab = "Recruitment Estimate",
          title = "Recruitment 1 Year Lag")


## 2 year lag
lm_rec_gsi2<-lm(recruit_est ~ mean_gsi_lag2, data=gsi_df)
summary(lm_rec_gsi2)

cor.test(gsi_df$recruit_est, gsi_df$mean_gsi_lag2, method=c("pearson"))

ggscatter(gsi_df, x = "mean_gsi_lag2", y = "recruit_est",
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.coeff.args = list(method="pearson"),
          add.params=list(color="dodgerblue", fill="lightgray"),
          xlab = "Mean Yearly GSI", ylab = "Recruitment Estimate",
          title = "Recruitment 2 Year Lag")

## 3 year lag
lm_rec_gsi3<-lm(mean_gsi_lag3 ~ recruit_est, data=gsi_df)
summary(lm_rec_gsi3)

cor.test(gsi_df$recruit_est, gsi_df$mean_gsi_lag3, method=c("pearson"))

ggscatter(gsi_df, x = "mean_gsi_lag3", y = "recruit_est",
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.coeff.args = list(method="pearson"),
          add.params=list(color="dodgerblue", fill="lightgray"),
          xlab = "Mean Yearly GSI", ylab = "Recruitment Estimate",
          title = "Recruitment 3 Year Lag")


## 6 year lag
lm_rec_gsi6<-lm(mean_gsi_lag6 ~ recruit_est, data=gsi_df)
summary(lm_rec_gsi6)

cor.test(gsi_df$recruit_est, gsi_df$mean_gsi_lag6, method=c("pearson"))

ggscatter(gsi_df, x = "mean_gsi_lag6", y = "recruit_est",
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.coeff.args = list(method="pearson"),
          add.params=list(color="dodgerblue", fill="lightgray"),
          xlab = "Mean Yearly GSI", ylab = "Recruitment Estimate",
          title = "Recruitment 6 Year Lag")

## 7 year lag
lm_rec_gsi7<-lm(mean_gsi_lag7 ~ recruit_est, data=gsi_df)
summary(lm_rec_gsi7)

cor.test(gsi_df$recruit_est, gsi_df$mean_gsi_lag7, method=c("pearson"))

ggscatter(gsi_df, x = "mean_gsi_lag7", y = "recruit_est",
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.coeff.args = list(method="pearson"),
          add.params=list(color="dodgerblue", fill="lightgray"),
          xlab = "Mean Yearly GSI", ylab = "Recruitment Estimate",
          title = "Recruitment 7 Year Lag")

```

**CPUE/Year lags - comparison to Nesslage ea 2023**
```{r}

sfob_yr<- dplyr::full_join(catch_recruit, gsi.m %>%
                   group_by(year) %>% 
                   summarise(m.gsi = mean(GSI),
                             sd.gsi = sd(GSI),
                             max.gsi = max(GSI), 
                             min.gsi = min(GSI)), 
                 by = join_by(year)) %>% 
  mutate(mean_gsi_lag1 = lag(m.gsi,1),
         mean_gsi_lag2 = lag(m.gsi,2),
         mean_gsi_lag3 = lag(m.gsi,3)) %>%
  mutate(pos = ifelse(m.gsi > 0, 'Northerly', 'Southerly'), 
         n.pos = ifelse(m.gsi > 0, 1, 0))
gsi_yr <- sfob_yr[-c(20:21,24:69),] #removes years not in study fleet and 2 outliers

## No lag
lm_cpue_gsi<-lm(m.gsi ~ ttl_sum, data=gsi_yr)
summary(lm_cpue_gsi)

cor.test(gsi_yr$ttl_sum, gsi_yr$m.gsi, method=c("pearson"))

ggscatter(gsi_yr, x = "m.gsi", y = "ttl_sum",
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.coeff.args = list(method="pearson"),
          add.params=list(color="dodgerblue", fill="lightgray"),
          xlab = "Mean Yearly GSI", ylab = "Total CPUE/year",
          title = "SFOB CPUE No Lag")


## 1 year lag
lm_cpue_gsi1<-lm(mean_gsi_lag1 ~ ttl_sum, data=gsi_yr)
summary(lm_cpue_gsi1)

cor.test(gsi_yr$ttl_sum, gsi_yr$mean_gsi_lag1, method=c("pearson"))

ggscatter(gsi_yr, x = "mean_gsi_lag1", y = "ttl_sum",
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.coeff.args = list(method="pearson"),
          add.params=list(color="dodgerblue", fill="lightgray"),
          xlab = "Mean Yearly GSI", ylab = "Total CPUE/year",
          title = "SFOB CPUE 1 Year Lag")


## 2 year lag
lm_cpue_gsi2<-lm(mean_gsi_lag2 ~ ttl_sum, data=gsi_yr)
summary(lm_cpue_gsi2)

cor.test(gsi_yr$ttl_sum, gsi_yr$mean_gsi_lag2, method=c("pearson"))

ggscatter(gsi_yr, x = "mean_gsi_lag2", y = "ttl_sum",
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.coeff.args = list(method="pearson"),
          add.params=list(color="dodgerblue", fill="lightgray"),
          xlab = "Mean Yearly GSI", ylab = "Total CPUE/year",
          title = "SFOB CPUE 2 Year Lag")


## 3 year lag
lm_cpue_gsi3<-lm(mean_gsi_lag3 ~ ttl_sum, data=gsi_yr)
summary(lm_cpue_gsi3)

cor.test(gsi_yr$ttl_sum, gsi_yr$mean_gsi_lag3, method=c("pearson"))

ggscatter(gsi_yr, x = "mean_gsi_lag3", y = "ttl_sum",
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.coeff.args = list(method="pearson"),
          add.params=list(color="dodgerblue", fill="lightgray"),
          xlab = "Mean Yearly GSI", ylab = "Total CPUE/year",
          title = "SFOB CPUE 3 Year Lag")


```


```{r}
 
gsi <- read.csv(here::here('C:/Users/stephanie.owen/Documents/tilefish_indicators/data/gulf_stream_index/gsi_sfob.csv'))

gsi_nozero <- filter(gsi, mean_cpue > 0, mean_cpue<15) #removes outlier

gsi.sfob<-mutate(gsi_nozero, pos = ifelse(GSI > 0, 'Northerly', 'Southerly'), 
         n.pos = ifelse(GSI > 0, 1, 0))

```


**Regressions and correlations CPUE and GSI - no lag**

```{r}
#correlations gsi and cpue
lm_gsi<-lm(GSI ~ mean_cpue, data=gsi.sfob)
summary(lm_gsi)

gsi.sfob = gsi.sfob %>% 
  mutate(season = case_when(month %in% c(1,2,3) ~ 'winter', 
                            month %in% c(4,5,6) ~ 'spring', 
                            month %in% c(7,8,9) ~ 'summer', 
                            month %in% c(10,11,12) ~ 'fall'))

cor.test(gsi.sfob$mean_cpue, gsi.sfob$GSI, method=c("pearson"))

# all months, color coded by season
ggscatter(gsi.sfob, x = "GSI", y = "mean_cpue", 
          add = "reg.line", conf.int = TRUE, 
          color="season", palette="Spectral",
          cor.coef = TRUE, cor.coeff.args = list(method="pearson"),
          add.params=list(color="dodgerblue", fill="lightgray"),
          xlab = "Mean Monthly GSI", ylab = "Monthly mean CPUE/hr",
          title = "Gulf stream index")

# plot by season
gsi.sfob %>% group_by(year, season) %>%
 ggscatter(x = "GSI", y = "mean_cpue", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.coeff.args = list(method="pearson"),
          add.params=list(color="dodgerblue", fill="lightgray"),
          xlab = "GSI", ylab = "Monthly Mean CPUE/hr",
          title = "Gulf Stream Index")+
  facet_wrap(~season, scales = 'free')
```

##### Cold pool


Excerpt from New York Bight Fish, Fisheries, and Sand Features: Data Review
Volume 1: Literature Synthesis and Gap Analysis: 

Natural events are documented for Scup (Morse 1978; Smith and Norcross 1968), Bluefish (Slater et al. 2007), and Northern Puffer (Wicklund 1970) in the MAB and NYB as a result of upwelling of cold bottom water, and for Golden Tilefish on the OCS from eastward flow of the Cold Pool (Fisher et al. 2014). Such events are
difficult to detect and quantify because they are episodic, because they could happen in winter when there are few observers, or because they leave dead animals on the bottom instead of floating (Fisher et al.2014) so that they are only detected incidentally by trawler (e.g., Woodhead (1964)).


Cold pool extent: 

Positive values == Larger
Negative values == Smaller

**Cold pool extent Regressions - No lag**

```{r}
## cold pool extent; yearly value, so no by season

library(ecodata)
# Pull cold pool data
cp <- ecodata::cold_pool
# Selecting just the extent
cp.ex <- cp %>% filter(Time %in% c(1994:2020), 
              Var == 'extent_index') %>%
          mutate(ext = Value,
              year = as.numeric(Time))

# Join with sfob yearly total cpue 
cp.sfob <- dplyr::full_join(sfob_yr, cp.ex, by = join_by(year)) %>%
  dplyr::select(year, ttl_sum, ext) %>% 
  filter(year %in% c(1998:2020))
cp.sfob <- cp.sfob[-c(20:21),] #remove outliers

cp.sfob %>% 
  ggscatter(x = 'ext', y = 'ttl_sum', 
            add = "reg.line", conf.int = TRUE, 
            cor.coef = TRUE, cor.coeff.args = list(method="pearson"),
            add.params=list(color="dodgerblue", fill="lightgray"),
            xlab = "Cold pool extent", ylab = "Annual Total CPUE",
            title="Cold pool extent No lag")

```

**Cold pool persistence Regression - No lag**

Persistence Index:
From tech doc: Model_PI measures the duration of the Cold Pool and is estimated using the month when bottom temperature rises above 10C after the Cold Pool is formed each year

Positive values == Longer
Negative values == Shorter

Result: Significant negative relationship between recruitment estimate and 
persistence of cold pool, recruitment declines with increased cold pool 
persistence. 

```{r}
cp.pers <- cp %>% filter(Time %in% c(1994:2020), 
              Var == 'persistence_index') %>%
  mutate(pers = Value,
         year = as.numeric(Time))

cp.sfob <- dplyr::full_join(sfob_yr, cp.pers, by = join_by(year)) %>%
  dplyr::select(year, ttl_sum, pers) %>% 
  filter(year %in% c(1998:2020))
cp.sfob <- cp.sfob[-c(20:21),] #remove outliers

cp.sfob %>% 
  ggscatter(x = 'pers', y = 'ttl_sum', 
            add = "reg.line", conf.int = TRUE, 
            cor.coef = TRUE, cor.coeff.args = list(method="pearson"),
            add.params=list(color="dodgerblue", fill="lightgray"),
            xlab = "Cold pool persistence", ylab = "Annual Total CPUE",
            title="Cold pool persistence no lag")
```
**Cold pool index Regression - no lag**

Cold pool index:

From tech doc: The Model_SEI is estimated by the number of cells where bottom temperature remains below 10C for at least 2 months between June and September.

Positive values == colder 
Negative values == warmer

Result: Linear positive trend is weak and non-signficant.

```{r}
cpi <- cp %>% filter(Time %in% c(1994:2020), 
              Var == 'cold_pool_index') %>%
  mutate(cpi = Value,
         year = as.numeric(Time))

cpi <- cpi %>%
  mutate(cpi_lag3 = lag(cpi,3)) #lag 3 years
         
cp.sfob <- dplyr::full_join(sfob_yr, cpi, by = join_by(year)) %>%
  dplyr::select(year, ttl_sum, cpi, cpi_lag3) %>% 
  filter(year %in% c(1998:2020))
cp.sfob <- cp.sfob[-c(20:21),] #remove outliers

cp.sfob %>% 
  ggscatter(x = 'cpi', y = 'ttl_sum', 
            add = "reg.line", conf.int = TRUE, 
            cor.coef = TRUE, cor.coeff.args = list(method="pearson"),
            add.params=list(color="dodgerblue", fill="lightgray"),
            xlab = "Cold pool index", ylab = "Annual Total CPUE",
            title="Cold pool index")

```

#### Food availablity 

Larval tilefish eat zooplankton, likely calanus.


##### Microplankton
```{r}
# microplankton
micro<-read.csv(here::here('data/phyto_size_class/microplankton_ts_gtf_strata.csv'))
```


##### Microplankton analysis

```{r}

# filter sfob.env 
sfob <- sfob.env %>% filter(depth > 50, cpue_hr > 0, cpue_hr<15) %>%
  group_by(year,month) %>% 
  summarise(mean_cpue = mean(cpue_hr)) 
         
# Join with sf/ob data
micro.sfob <- dplyr::full_join(micro, sfob, by = join_by(year, month)) %>%
  dplyr::select(year, month, mean_cpue, mean_micro, weighted_mean_micro) %>%
  tidyr::drop_na()
```
**Micro Regressions and correlation - no lag**

```{r}
# Correlation and plot
lm_micro<-lm(weighted_mean_micro ~ mean_cpue, data=micro.sfob)
summary(lm_micro)

micro.sfob = micro.sfob %>% 
  mutate(season = case_when(month %in% c(1,2,3) ~ 'winter', 
                            month %in% c(4,5,6) ~ 'spring', 
                            month %in% c(7,8,9) ~ 'summer', 
                            month %in% c(10,11,12) ~ 'fall'))

cor.test(micro.sfob$mean_cpue, micro.sfob$weighted_mean_micro, method=c("pearson"))

#all months, color coded by season
ggscatter(micro.sfob, x = "weighted_mean_micro", y = "mean_cpue", 
          add = "reg.line", conf.int = TRUE, 
          color="season", palette="Spectral",
          cor.coef = TRUE, cor.coeff.args = list(method="pearson"),
          add.params=list(color="dodgerblue", fill="lightgray"),
          xlab = "Weighted mean microplankton", ylab = "Monthly mean CPUE/hr",
          title = "Microplankton no lag")

# by season
micro.sfob %>% group_by(year, season) %>%
 ggscatter(x = "weighted_mean_micro", y = "mean_cpue", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.coeff.args = list(method="pearson"),
          add.params=list(color="dodgerblue", fill="lightgray"),
          xlab = "Weighted Mean Microplankton", ylab = "Monthly Mean CPUE/hr",
          title = "Microplankton no lag")+
  facet_wrap(~season, scales = 'free')

```


##### Chlorophyll-A
```{r}

# CHL-A
chl<-read.csv(here::here('data/chl/chl_ts_gtf_strata.csv'))
```

##### Chlorophyll-A analysis

```{r, c21}

# filter sfob.env 
sfob <- sfob.env %>% filter(depth > 50, cpue_hr > 0, cpue_hr<15) %>%
  group_by(year,month) %>% 
  summarise(mean_cpue = mean(cpue_hr)) 
         
# Join with sf/ob data
chl.sfob <- dplyr::full_join(chl, sfob, by = join_by(year, month)) %>%
  dplyr::select(year, month, mean_cpue, mean_chl, weighted_mean_chl) %>%
  tidyr::drop_na()

```

**CHL-a Regression and correlation - no lag**

```{r}
lm_chl<-lm(weighted_mean_chl ~ mean_cpue, data=chl.sfob)
summary(lm_chl)

chl.sfob = chl.sfob %>% 
  mutate(season = case_when(month %in% c(1,2,3) ~ 'winter', 
                            month %in% c(4,5,6) ~ 'spring', 
                            month %in% c(7,8,9) ~ 'summer', 
                            month %in% c(10,11,12) ~ 'fall'))

cor.test(chl.sfob$mean_cpue, chl.sfob$weighted_mean_chl, method=c("pearson"))

#all seasons - color coded
ggscatter(chl.sfob, x = "weighted_mean_chl", y = "mean_cpue", 
          add = "reg.line", conf.int = TRUE, 
          color="season", palette="Spectral",
          cor.coef = TRUE, cor.coeff.args = list(method="pearson"),
          add.params=list(color="dodgerblue", fill="lightgray"),
          xlab = "Weighted mean CHL-a", ylab = "Monthly mean CPUE/hr",
          title = "CHL-a")

#by season
chl.sfob %>% group_by(year, season) %>%
 ggscatter(x = "weighted_mean_chl", y = "mean_cpue", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.coeff.args = list(method="pearson"),
          add.params=list(color="dodgerblue", fill="lightgray"),
          xlab = "Weighted Mean Chlorophyll-a", ylab = "Monthly Mean CPUE/hr",
          title = "Chlorophyll-a")+
  facet_wrap(~season, scales = 'free')
```











